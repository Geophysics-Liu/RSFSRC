\author{Sir Charles Antony Richard Hoare}
%%%%%%%%%%%%%%%%%%%%%
\title{Homework 2}

\begin{abstract}
  This homework has four parts. 
  \begin{enumerate}
  \item Theoretical questions related to data attributes.
  \item Measuring the performance of sorting algorithms.
  \item Analyzing a digital elevation map by applying a running average filter.
  \item Analyzing your own data by applying a running average filter.
  \end{enumerate}
\end{abstract}

\section{Prerequisites}

Completing the computational part of this homework assignment requires
\begin{itemize}
\item \texttt{Madagascar} software environment available from \\
\url{http://www.ahay.org/}
\item \LaTeX\ environment with \texttt{SEG}\TeX\ available from \\ 
\url{http://www.ahay.org/wiki/SEGTeX}
\end{itemize}
To do the assignment on your personal computer, you need to install
the required environments. Please ask for help if you don't know where
to start.

The homework code is available from the \texttt{Madagascar} repository
by running
\begin{verbatim}
svn co http://svn.code.sf.net/p/rsf/code/trunk/book/geo391/hw2
\end{verbatim}

\section{Data attributes}

You can either write your answers to theoretical questions on paper or
edit them in the file \texttt{hw2/paper.tex}. Please show all the
mathematical derivations that you perform.


\begin{enumerate}

\item The varimax attribute is defined as
\begin{equation}
  \label{eq:varimax}
\phi[\mathbf{a}] = \frac{\displaystyle N\,\sum\limits_{n=1}^N
  a_n^4}{\displaystyle \left(\sum\limits_{n=1}^{N} a_n^2\right)^2}
\end{equation}

Suppose that the data vector $\mathbf{a}$ consists of random noise:
the data values $a_n$ are independent and identically distributed with
a zero-mean Gaussian distribution: $E[a_n]=0$, $E[a_n^2]=\sigma^2$,
$E[a_n^4]=3\,\sigma^4$. Find the mathematical expectation of
$\phi[\mathbf{a}]$.

\item The \emph{skewness} attribute evaluates the asymmetry of the data
  distribution. For zero-mean data, it is defined as
\begin{equation}
  \label{eq:skewness}
\kappa[\mathbf{a}] = \frac{\displaystyle \sum\limits_{n=1}^N
  a_n^3}{\displaystyle \left(\frac{1}{N}\,\sum\limits_{n=1}^{N} a_n^2\right)^{3/2}}\;.
\end{equation}

Define skewness squared $\kappa^2[\mathbf{a}]$ in terms of the similarity
measure (squared correlation coefficient) 
\begin{equation}
\label{eq:gamma}
\gamma^2[\mathbf{a},\mathbf{b}] = 
\frac{\displaystyle \left(\sum\limits_{n=1}^N a_n\,b_n\right)^2}{\displaystyle \sum\limits_{n=1}^N a_n^2\,\sum\limits_{n=1}^N b_n^2}\;.
\end{equation}

\end{enumerate}

\section{Sorting algorithms}
\inputdir{sorting}

\begin{enumerate}          
\item Change directory to \texttt{hw2/sorting}.
\item Run
\begin{verbatim}
scons movie.vpl
\end{verbatim}
and observe a movie illustrating the slow data sorting algorithm. The
algorithm is implemented in the \texttt{slow\_sort} function in the
file \texttt{sorting.c}.

\item Run
\begin{verbatim}
scons view
\end{verbatim}
to compute the cost of slow sorting experimentally. The output is
shown in Figure~\ref{fig:cost}.

\sideplot{cost}{width=\textwidth}{Experimental cost of slow sorting. 
The logarithm of the cost is shown against the logarithm of the data size.}

If we approximate the cost as $P(N)=C\,N^\epsilon$, what is the value of
$\epsilon$ observed in the picture?

\item Open the file \texttt{sorting.c} in a text editor and edit it to 
fix the specified line in the \texttt{quick\_sort} function.

\item Open the file \texttt{SConstruct} in a text editor and uncomment 
      the specified line.

\item Rerun
\begin{verbatim}
scons movie.vpl
\end{verbatim}
to observe a change in the sorting movie. Debug your changes to the
program if necessary.

\item Run
\begin{verbatim}
scons view
\end{verbatim}
to observe the change in the algorithm cost. What is the new
experimental value of $\epsilon$?

\item \textbf{EXTRA CREDIT} for improving the speed of the 
\texttt{quick\_sort} algorithm even further.
\end{enumerate}

\lstset{language=c,numbers=left,numberstyle=\tiny,showstringspaces=false}
\lstinputlisting[frame=single,title=sorting/sorting.c]{sorting/sorting.c}

\lstset{language=python,numbers=left,numberstyle=\tiny,showstringspaces=false}
\lstinputlisting[frame=single,title=sorting/SConstruct]{sorting/SConstruct}

\section{Running median and running mean filters}
\inputdir{running}

\sideplot{dem}{width=0.9\textwidth}{Digital elevation map of the 
west Austin area.}

We return the digital elevation map of the West Austin Area, shown in Figure~\ref{fig:dem}.

In this exercise, we will separate the data into ``signal'' and
``noise'' by applying running mean and median filters.  The result of
applying a running median filter is shown in
Figure~\ref{fig:ave,res}. Running median effectively smooths the data
by removing local outliers.

\multiplot{2}{ave,res}{width=0.45\textwidth}{Data separated into
  signal (a) and noise (b) by applying a running median filter.}

The algorithm is implemented in program \texttt{running.c}.

\lstset{language=c,numbers=left,numberstyle=\tiny,showstringspaces=false}
\lstinputlisting[frame=single,title=running/running.c]{running/running.c}

\begin{enumerate}
\item Change directory to \texttt{hw2/running}.
\item Run 
\begin{verbatim}
scons view
\end{verbatim}
to reproduce the figures on your screen.
\item Modify the \texttt{running.c} program and the
  \texttt{SConstruct} file to compute running mean instead of running
  median. Compare the results.
\item \textbf{EXTRA CREDIT} for improving the efficiency of the
  running median algorithm. Run
\begin{verbatim}
scons time.vpl
\end{verbatim}
  to display a figure that compares the efficiency of running median
  computations using the slow sorting from function \texttt{median} in
  program \texttt{running.c} and the fast quantile algorithm (library
  function \texttt{sf\_quantile} ). Your goal is to make the algorithm
  even faster. Consider parallelization, reusing previous windows,
  other fast sorting strategies, etc.
\end{enumerate}

\lstset{language=python,numbers=left,numberstyle=\tiny,showstringspaces=false}
\lstinputlisting[frame=single,title=running/SConstruct]{running/SConstruct}

\section{Your own data}

Your final task is to apply the technique of the previous section to
your own data:
\begin{enumerate}
\item Select a dataset suitable for running mean/median filters.
\item Apply the algorithm of the previous section and choose
  appropriate parameters.
\item Include the results in your homework.
\end{enumerate}

\newpage

\section{Completing the assignment}

\begin{enumerate}
\item Change directory to \texttt{hw2}.
\item Edit the file \texttt{paper.tex} in your favorite editor and change the
  first line to have your name instead of Hoare's.
\item Run
\begin{verbatim}
sftour scons lock
\end{verbatim}
to update all figures.
\item Run
\begin{verbatim}
sftour scons -c
\end{verbatim}
to remove intermediate files.
\item Run
\begin{verbatim}
scons pdf
\end{verbatim}
to create the final document.
\item Submit your result (file \texttt{paper.pdf}) on paper or by
e-mail.
\end{enumerate}
